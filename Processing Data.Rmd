---
title: "NutNet Phenology with NDVI"
author: "Ellen Esch"
date: "`r format(Sys.time(), '%d %B %Y')`"
# output:
#   word_document: default
#   pdf_document: default
#   html_document: default
output: 
  github_document:
    toc: true
urlcolor: blue
---

```{r packages, include=F, echo=F, message=F}
library("tidyverse")
library("sf")
library("rnaturalearth")
library("cowplot")
library("lubridate")
library("raster")
```

# Overview

This document walks through the steps necessary to:
-
-


Please change `process_raw` equal to `TRUE` if you need to download and process raw data. In most cases, this will likely remain as `FALSE`, becuase intermediate (processed) files *are* stored on GitHub. 

You'll need to read in the location of the sites being used in this analysis.
You'll also need to store some files on your local machine, so set a path to your desired location.

```{r filelocations, }
sites <- read_csv('./data/NutNetGreening_2019.10.15_ee.csv', col_types = cols())
localdir <- "/Users/ellen/Desktop/Ellen/Guelph/Project_Andrew phenology/pheno_localdata"

process_raw <- FALSE #TRUE
```

```{r moresetup, echo=F, include = F}
#for some of the analyses need to change the spatial form
sites_nutnet <- sites %>%
  dplyr::select(site_code, "GEE coordinates") %>%
  separate("GEE coordinates", sep = ',', into = c('long', 'lat')) %>%
  filter(!is.na(long)) %>%
  mutate(lat = as.numeric(lat), long = as.numeric(long))
sites_nutnet_sp <- sites_nutnet
coordinates(sites_nutnet_sp) <- ~long + lat

sites_nutnet_sp2<- sites_nutnet_sp %>% st_as_sf()
```

And just for fun, here is a map of the sites in this analysis

```{r sitemap, echo=F}
world <- ne_countries(scale = "medium", returnclass = "sf")
(ggplot(data = world, label = site)+
  geom_sf() +
  geom_point(data = sites, aes (x = longitude, y = latitude), col = "orange2") +
  theme_bw()+
  labs(title = "111 sites in analysis here"))
```

## Process weather & climate data

**Skip to step 5 if not needing to re-create data. Steps 1-4 walk through raw data downloads.**

1) Download montly [precipitation data](http://data.ceda.ac.uk/badc/cru/data/cru_ts/cru_ts_4.04/data/pre) onto your local machine (large files). You will have to either create an account or log in. Download 4 time periods (you want the files with the 'nc' in the name):

- 1981-1990
- 1991-2000
- 2001-2010
- 2011-2019

```{r precipdata, echo=F}
### create precipitation data for the 4 distinct time periods
if (process_raw == TRUE) {
cruv <- "pre"
timeframe <- '1981.1990.'
source("./get-CRU-TS.R")

timeframe <- '1991.2000.'
source("./get-CRU-TS.R")

timeframe <- '2001.2010.'
source("./get-CRU-TS.R")

timeframe <- '2011.2019.'
source("./get-CRU-TS.R")

} else print("not processing raw data")
```


2) Repeat with montly [temperature data](http://data.ceda.ac.uk/badc/cru/data/cru_ts/cru_ts_4.04/data/tmp).


```{r temperaturedata, echo = F}
if (process_raw == TRUE) {
cruv <- 'tmp'
timeframe <- '1981.1990.'
source("./get-CRU-TS.R")

timeframe <- '1991.2000.'
source("./get-CRU-TS.R")

timeframe <- '2001.2010.'
source("./get-CRU-TS.R")

timeframe <- '2011.2019.'
source("./get-CRU-TS.R")
} else print("not processing raw data")

```

3) Write a dataframe with merged monthly temperature and precipitation data

```{r climatedf, echo=F}
if (process_raw == TRUE) {
eightys <- read_csv("./data/weather/CRU-monthly-tmp1981.1990.csv", col_types = cols()) %>% 
  full_join(read_csv("./data/weather/CRU-monthly-pre1981.1990.csv", col_types = cols())) %>%
  dplyr::select(-date, -month, -year)

ninetys <- read_csv("./data/weather/CRU-monthly-tmp1991.2000.csv", col_types = cols()) %>% 
  full_join(read_csv("./data/weather/CRU-monthly-pre1991.2000.csv", col_types = cols())) %>%
  dplyr::select(-date, -month, -year)

thousands <- read_csv("./data/weather/CRU-monthly-tmp2001.2010.csv", col_types = cols()) %>% 
  full_join(read_csv("./data/weather/CRU-monthly-pre2001.2010.csv", col_types = cols())) %>%
  dplyr::select(-date, -month, -year)

tens <- read_csv("./data/weather/CRU-monthly-tmp2011.2019.csv", col_types = cols()) %>% 
  full_join(read_csv("./data/weather/CRU-monthly-pre2011.2019.csv", col_types = cols())) %>%
  dplyr::select(-date, -month, -year)

monthlyweather <- bind_rows(eightys, ninetys, thousands, tens) %>%
  rename(sitename = site_code) %>% 
  mutate(Month = month(plotdate)) 

write.csv(
  monthlyweather,
  './data/weather/monthlyweather.csv',
  row.names = F
)
} else print("not processing raw data")

```

4) Download [30 year averages from WorldClim](https://www.worldclim.org/data/worldclim21.html) onto your local machine. Download the most detailed spatial level (30 seconds) for:

- average temperature (tavg_30s)
- precipitaiton (preci_30s)

```{r worldclim, echo=F}
if (process_raw == TRUE) {

#####
# temperature
#####

WC1 <- raster(paste0(localdir, '/wc2.1_30s_tavg_01.tif'))
wc1 <- raster::extract(WC1, sites_nutnet_sp2, fun = max, df = TRUE) %>% 
  mutate(sitename = sites_nutnet_sp2$site_code)

WC2 <- raster(paste0(localdir, '/wc2.1_30s_tavg_02.tif'))
wc2 <- raster::extract(WC2, sites_nutnet_sp2, fun = max, df = TRUE) %>% 
  mutate(sitename = sites_nutnet_sp2$site_code)

WC3 <- raster(paste0(localdir, '/wc2.1_30s_tavg_03.tif'))
wc3 <- raster::extract(WC3, sites_nutnet_sp2, fun = max, df = TRUE) %>% 
  mutate(sitename = sites_nutnet_sp2$site_code)

WC4 <- raster(paste0(localdir, '/wc2.1_30s_tavg_04.tif'))
wc4 <- raster::extract(WC4, sites_nutnet_sp2, fun = max, df = TRUE) %>% 
  mutate(sitename = sites_nutnet_sp2$site_code)

WC5 <- raster(paste0(localdir, '/wc2.1_30s_tavg_05.tif'))
wc5 <- raster::extract(WC5, sites_nutnet_sp2, fun = max, df = TRUE) %>% 
  mutate(sitename = sites_nutnet_sp2$site_code)

WC6 <- raster(paste0(localdir, '/wc2.1_30s_tavg_06.tif'))
wc6 <- raster::extract(WC6, sites_nutnet_sp2, fun = max, df = TRUE) %>% 
  mutate(sitename = sites_nutnet_sp2$site_code)

WC7 <- raster(paste0(localdir, '/wc2.1_30s_tavg_07.tif'))
wc7 <- raster::extract(WC7, sites_nutnet_sp2, fun = max, df = TRUE) %>% 
  mutate(sitename = sites_nutnet_sp2$site_code)

WC8 <- raster(paste0(localdir, '/wc2.1_30s_tavg_08.tif'))
wc8 <- raster::extract(WC8, sites_nutnet_sp2, fun = max, df = TRUE) %>% 
  mutate(sitename = sites_nutnet_sp2$site_code)

WC9 <- raster(paste0(localdir, '/wc2.1_30s_tavg_09.tif'))
wc9 <- raster::extract(WC9, sites_nutnet_sp2, fun = max, df = TRUE) %>% 
  mutate(sitename = sites_nutnet_sp2$site_code)

WC10 <- raster(paste0(localdir, '/wc2.1_30s_tavg_10.tif'))
wc10 <- raster::extract(WC10, sites_nutnet_sp2, fun = max, df = TRUE) %>% 
  mutate(sitename = sites_nutnet_sp2$site_code)

WC11 <- raster(paste0(localdir, '/wc2.1_30s_tavg_11.tif'))
wc11 <- raster::extract(WC11, sites_nutnet_sp2, fun = max, df = TRUE) %>% 
  mutate(sitename = sites_nutnet_sp2$site_code)

WC12 <- raster(paste0(localdir, '/wc2.1_30s_tavg_12.tif'))
wc12 <- raster::extract(WC12, sites_nutnet_sp2, fun = max, df = TRUE) %>% 
  mutate(sitename = sites_nutnet_sp2$site_code)


AvgClimate <- full_join(wc1, wc2, by = c("ID", "sitename")) %>%
  full_join(wc3, by = c("ID", "sitename")) %>%
  full_join(wc4, by = c("ID", "sitename")) %>%
  full_join(wc5, by = c("ID", "sitename")) %>%
  full_join(wc6, by = c("ID", "sitename")) %>%
  full_join(wc7, by = c("ID", "sitename")) %>%
  full_join(wc8, by = c("ID", "sitename")) %>%
  full_join(wc9, by = c("ID", "sitename")) %>%
  full_join(wc10, by = c("ID", "sitename")) %>%
  full_join(wc11, by = c("ID", "sitename")) %>%
  full_join(wc12, by = c("ID", "sitename"))  %>%
  gather(Month, AvgTempLTA, -ID, -sitename) %>%
  mutate(Month = recode(Month, "wc2.1_30s_tavg_01" = 1,
                        "wc2.1_30s_tavg_02" = 2, 
                        "wc2.1_30s_tavg_03" = 3,
                        "wc2.1_30s_tavg_04" = 4, 
                        "wc2.1_30s_tavg_05" = 5,
                        "wc2.1_30s_tavg_06" = 6,
                        "wc2.1_30s_tavg_07" = 7, 
                        "wc2.1_30s_tavg_08" = 8, 
                        "wc2.1_30s_tavg_09" = 9,
                        "wc2.1_30s_tavg_10" = 10,
                        "wc2.1_30s_tavg_11" = 11,
                        "wc2.1_30s_tavg_12" = 12)) 


####
#precip
#####

preWC1 <- raster(paste0(localdir, '/wc2.1_30s_prec_01.tif'))
prewc1 <- raster::extract(preWC1, sites_nutnet_sp2, fun = max, df = TRUE) %>% 
  mutate(sitename = sites_nutnet_sp2$site_code)

preWC2 <- raster(paste0(localdir, '/wc2.1_30s_prec_02.tif'))
prewc2 <- raster::extract(preWC2, sites_nutnet_sp2, fun = max, df = TRUE) %>% 
  mutate(sitename = sites_nutnet_sp2$site_code)

preWC3 <- raster(paste0(localdir, '/wc2.1_30s_prec_03.tif'))
prewc3 <- raster::extract(preWC3, sites_nutnet_sp2, fun = max, df = TRUE) %>% 
  mutate(sitename = sites_nutnet_sp2$site_code)

preWC4 <- raster(paste0(localdir, '/wc2.1_30s_prec_04.tif'))
prewc4 <- raster::extract(preWC4, sites_nutnet_sp2, fun = max, df = TRUE) %>% 
  mutate(sitename = sites_nutnet_sp2$site_code)

preWC5 <- raster(paste0(localdir, '/wc2.1_30s_prec_05.tif'))
prewc5 <- raster::extract(preWC5, sites_nutnet_sp2, fun = max, df = TRUE) %>% 
  mutate(sitename = sites_nutnet_sp2$site_code)

preWC6 <- raster(paste0(localdir, '/wc2.1_30s_prec_06.tif'))
prewc6 <- raster::extract(preWC6, sites_nutnet_sp2, fun = max, df = TRUE) %>% 
  mutate(sitename = sites_nutnet_sp2$site_code)

preWC7 <- raster(paste0(localdir, '/wc2.1_30s_prec_07.tif'))
prewc7 <- raster::extract(preWC7, sites_nutnet_sp2, fun = max, df = TRUE) %>% 
  mutate(sitename = sites_nutnet_sp2$site_code)

preWC8 <- raster(paste0(localdir, '/wc2.1_30s_prec_08.tif'))
prewc8 <- raster::extract(preWC8, sites_nutnet_sp2, fun = max, df = TRUE) %>% 
  mutate(sitename = sites_nutnet_sp2$site_code)

preWC9 <- raster(paste0(localdir, '/wc2.1_30s_prec_09.tif'))
prewc9 <- raster::extract(preWC9, sites_nutnet_sp2, fun = max, df = TRUE) %>% 
  mutate(sitename = sites_nutnet_sp2$site_code)

preWC10 <- raster(paste0(localdir, '/wc2.1_30s_prec_10.tif'))
prewc10 <- raster::extract(preWC10, sites_nutnet_sp2, fun = max, df = TRUE) %>% 
  mutate(sitename = sites_nutnet_sp2$site_code)

preWC11 <- raster(paste0(localdir, '/wc2.1_30s_prec_11.tif'))
prewc11 <- raster::extract(preWC11, sites_nutnet_sp2, fun = max, df = TRUE) %>% 
  mutate(sitename = sites_nutnet_sp2$site_code)

preWC12 <- raster(paste0(localdir, '/wc2.1_30s_prec_12.tif'))
prewc12 <- raster::extract(preWC12, sites_nutnet_sp2, fun = max, df = TRUE) %>% 
  mutate(sitename = sites_nutnet_sp2$site_code)


AvgClimatePrecip <- full_join(prewc1, prewc2, by = c("ID", "sitename")) %>%
  full_join(prewc3, by = c("ID", "sitename")) %>%
  full_join(prewc4, by = c("ID", "sitename")) %>%
  full_join(prewc5, by = c("ID", "sitename")) %>%
  full_join(prewc6, by = c("ID", "sitename")) %>%
  full_join(prewc7, by = c("ID", "sitename")) %>%
  full_join(prewc8, by = c("ID", "sitename")) %>%
  full_join(prewc9, by = c("ID", "sitename")) %>%
  full_join(prewc10, by = c("ID", "sitename")) %>%
  full_join(prewc11, by = c("ID", "sitename")) %>%
  full_join(prewc12, by = c("ID", "sitename"))  %>%
  gather(Month, AvgPrecipLTA, -ID, -sitename) %>%
  mutate(Month = recode(Month, "wc2.1_30s_prec_01" = 1,
                        "wc2.1_30s_prec_02" = 2, 
                        "wc2.1_30s_prec_03" = 3,
                        "wc2.1_30s_prec_04" = 4, 
                        "wc2.1_30s_prec_05" = 5,
                        "wc2.1_30s_prec_06" = 6,
                        "wc2.1_30s_prec_07" = 7, 
                        "wc2.1_30s_prec_08" = 8, 
                        "wc2.1_30s_prec_09" = 9,
                        "wc2.1_30s_prec_10" = 10,
                        "wc2.1_30s_prec_11" = 11,
                        "wc2.1_30s_prec_12" = 12)) 


longterm_climate <- full_join(AvgClimate, AvgClimatePrecip)

write.csv(
  longterm_climate,
  './data/weather/longterm_avgclimate.csv',
  row.names = F
)

} else print("not processing raw data")


```

5) Look at the monthly deviations from the long term average. 

A plot illustrate a problem here (with an easy solution). At Cowichan there are no consistent longitudinal trends, but it is obvious that worldclim (long term average) and ceda (montly) data don't always necessarily align (expected becuase they have differnt methods, resolutions, etc.). This suggests that ceda should be used to calculate averages (1981-2019, 39 years) as well as anomolies. 


```{r weatherdev, echo=F, message=F, warning=F}
worldclim <- read_csv("./data/weather/longterm_avgclimate.csv")
montlycru <- read_csv("./data/weather/monthlyweather.csv")

#ceda precip in mm/month
#world clim is also in mm/month
ClimChange_wc <- montlycru %>% 
  full_join(worldclim) %>%
  mutate(TempDifference = tmp_degrees_Celsius - AvgTempLTA) %>%
  mutate(PrecipDifference = `pre_mm/month` - AvgPrecipLTA) %>%
  separate(sitename, into = c('site', 'b'), sep = "[.]") %>%
  dplyr::select(-b)

# ClimChange_wc %>% filter(site=="sval") %>%
#   ggplot(aes(x=plotdate, y=TempDifference))+
#   geom_point()+
#   geom_smooth(method = "lm")+
#   facet_wrap(~Month)+
#   labs(y = "Anomaly from 1970-2000, celsius", x = "Year", title = "Temperature Anomalies, Svalbard")+
#   theme_cowplot()+
#   geom_hline(yintercept = 0)+
#   scale_x_date(limits = c(ymd("1984-01-01"), ymd("2020-01-01")), date_breaks = "10 years", date_labels = "%Y") +
#   theme(axis.text.x = element_text(angle = 45, hjust = 1))

ClimChange_wc %>% filter(site=="cowi") %>%
  ggplot(aes(x=plotdate, y=PrecipDifference))+
  geom_point()+
  geom_smooth(method = "lm")+
  facet_wrap(~Month)+
  labs(y = "Anomaly from 1970-2000, mm", x = "Year", title = "Precip Anomalies, Cowichan")+
  theme_cowplot()+
  geom_hline(yintercept = 0)+
  scale_x_date(limits = c(ymd("1984-01-01"), ymd("2020-01-01")), date_breaks = "10 years", date_labels = "%Y") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


Indeed, using CEDA data to calculate averages as well as anomolies proves to be a much more logical metric. Cowichan data seems *much* more logical now. 


```{r ceda_avg, echo=F, message=F, warning=F}
# min(montlycru$plotdate)
# max(montlycru$plotdate)

cruavg <- montlycru %>% 
  group_by(sitename, Month) %>%
  summarise(avg_precip = mean(`pre_mm/month`, na.rm = T),
         avg_temp = mean(`tmp_degrees_Celsius`, na.rm = T), 
         N = n())

ClimChange <- montlycru %>%
  full_join(cruavg) %>%
  mutate(TempDifference = tmp_degrees_Celsius - avg_temp) %>%
  mutate(PrecipDifference = `pre_mm/month` - avg_precip) %>%
  separate(sitename, into = c('site', 'b'), sep = "[.]") %>%
  dplyr::select(-b)

# ClimChange %>% filter(site=="sval") %>%
#   ggplot(aes(x=plotdate, y=TempDifference))+
#   geom_point()+
#   geom_smooth(method = "lm")+
#   facet_wrap(~Month)+
#   labs(y = "Anomaly from 39 yrs CEDA data, celsius", x = "Year", title = "Temperature Anomalies, Svalbard")+
#   theme_cowplot()+
#   geom_hline(yintercept = 0)+
#   scale_x_date(limits = c(ymd("1984-01-01"), ymd("2020-01-01")), date_breaks = "10 years", date_labels = "%Y") +
#   theme(axis.text.x = element_text(angle = 45, hjust = 1))

ClimChange %>% filter(site=="cowi") %>%
  ggplot(aes(x=plotdate, y=PrecipDifference))+
  geom_point()+
  geom_smooth(method = "lm")+
  facet_wrap(~Month)+
  labs(y = "Anomaly from 39 yrs CEDA data, mm", x = "Year", title = "Precip Anomalies, Cowichan")+
  theme_cowplot()+
  geom_hline(yintercept = 0)+
  scale_x_date(limits = c(ymd("1984-01-01"), ymd("2020-01-01")), date_breaks = "10 years", date_labels = "%Y") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

## Nitrogen deposition data

Download data onto local machine. **NOTE: this is not currently working; projections issue not registering....**

```{r ndep, echo=F, include=F}
# ndep <- raster(paste0(localdir, '/N-deposition1993.tif'),
#                crs = '+init=EPSG:4326')
# crs(ndep) <- CRS('+init=EPSG:4326') #https://epsg.io/4326
# 
# ndep_merge <- raster::extract(ndep, sites_nutnet_sp2, fun = max, df = TRUE) %>%
#   mutate(sitename = sites_nutnet_sp2$site_code) %>%
#   separate(sitename, into = c('site', 'b'), sep = "[.]") %>%
#   dplyr::select(-b, -ID)
```
